{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uses Snow water equivalent from Margulis, S. A., G. Cortés, M. Girotto, and M. Durand (2016a), A Landsat-era Sierra Nevada (USA) snow reanalysis (1985–2015), J. Hydrometeorol., doi:10.1175/JHM-D-15-0177.1.\n",
    "\n",
    "Aggregates each .h5 file (one for each year) according to a defined mask (included cells=1, otherwise no_data), matching the mask spatial resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import numpy as np\n",
    "import h5py\n",
    "import netCDF4 as nc\n",
    "import time\n",
    "from datetime import datetime, timedelta, date\n",
    "import calendar\n",
    "from netCDF4 import num2date, date2num\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import iris\n",
    "import cf_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indir=os.path.normpath(\"X:/zraid_data5/ucla/snow/SWE\")\n",
    "maskdir=os.path.normpath(\"X:/projects/ucla/vic/gis\")\n",
    "outdir=os.path.normpath(\"X:/zraid_data5/ucla/snow\")\n",
    "mask=\"%s\\%s\" % (maskdir,\"vicbasins_mask.nc\")\n",
    "start_year=2007\n",
    "end_year=2015\n",
    "V='SWE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cube mask dims:\n",
      "(128, 112)\n",
      "[u'SWE', u'lat', u'lon']\n",
      "<HDF5 dataset \"SWE\": shape (365, 5701, 6601), type \"<i2\">\n",
      "(365, 5701, 6601)\n",
      "365 6601 5701\n",
      "data_agg_shape:\n",
      "(365L, 128L, 112L)\n",
      "day 30 of 365\n",
      "day 60 of 365\n",
      "day 90 of 365\n",
      "day 120 of 365\n",
      "day 150 of 365\n",
      "day 180 of 365"
     ]
    }
   ],
   "source": [
    "#load mask\n",
    "cube_mask = iris.load_cube(mask, 'mask')\n",
    "cube_mask.coord('longitude').guess_bounds()\n",
    "cube_mask.coord('latitude').guess_bounds()\n",
    "print \"Cube mask dims:\"\n",
    "print cube_mask.shape\n",
    "cube_mask.data = np.ma.masked_less(cube_mask.data, 1)\n",
    "\n",
    "# Open file. DATAFIELD_NAMEs found from gdalinfo <filename>\n",
    "DATAFIELD_NAME = '//SWE'\n",
    "\n",
    "for year in range(start_year, end_year+1):\n",
    "    FILE_NAME=\"%s\\SN_%s_WY%d.h5\" % (indir,V,year)\n",
    "    outf=\"%s\\SN_%s_WY%d.nc\" % (outdir,V,year)\n",
    "\n",
    "    with h5py.File(FILE_NAME, mode='r') as f:\n",
    "        # List available datasets.\n",
    "        print f.keys()\n",
    "\n",
    "        # Read dataset.\n",
    "        dset = f[DATAFIELD_NAME]\n",
    "        print dset\n",
    "        print dset.shape #original coords are TXY\n",
    "        ny=dset.shape[2]\n",
    "        nx=dset.shape[1]\n",
    "        nt=dset.shape[0]\n",
    "        print nt,ny,nx\n",
    "\n",
    "        #SET MASK DIMS TO NP ARRAY, THEN FILL WITH EACH DAY\n",
    "        data_agg_3d = np.empty([dset.shape[0], cube_mask.shape[0], cube_mask.shape[1]], dtype='f')\n",
    "        print \"data_agg_shape:\"\n",
    "        print data_agg_3d.shape\n",
    "\n",
    "        for j in range(nt):\n",
    "            if (j+1)%30==0:\n",
    "                print \"day \" + str(j+1) + \" of \" + str(nt)\n",
    "            data = np.array(dset[j]) #extracting one day drops time dimension\n",
    "            #original data has swapped x,y axes (SWE.axis('TXY')) - switch to typical CF TYX\n",
    "            data = data.swapaxes(0, 1)\n",
    "            data = np.where(data >= 0, data, np.nan)\n",
    "\n",
    "            if j==0:\n",
    "                #load lats and lons\n",
    "                Latd = f['//lat']\n",
    "                Lats = np.array(Latd[0,:])\n",
    "                Lond = f['//lon']\n",
    "                Lons = np.array(Lond[:,0])\n",
    "\n",
    "                lat_coord = iris.coords.DimCoord(Lats,standard_name='latitude',units='degrees')\n",
    "                lon_coord = iris.coords.DimCoord(Lons,standard_name='longitude',units='degrees')\n",
    "\n",
    "            cube_data = iris.cube.Cube(data,dim_coords_and_dims=[(lat_coord, 0),(lon_coord, 1)])\n",
    "            if not isinstance(cube_data.coord('longitude').bounds, np.ndarray):\n",
    "                cube_data.coord('longitude').guess_bounds()\n",
    "            if not isinstance(cube_data.coord('latitude').bounds, np.ndarray):\n",
    "                cube_data.coord('latitude').guess_bounds()\n",
    "            #couldn't get static regridder to work - this is not as efficient but works\n",
    "            scheme = iris.analysis.AreaWeighted(mdtol=0.5)\n",
    "            data_agg = cube_data.regrid(cube_mask, scheme)\n",
    "\n",
    "            data_agg_3d[j,:,:]=data_agg.data\n",
    "\n",
    "        try:\n",
    "            dset.close()\n",
    "        except:\n",
    "            pass # Was already closed        \n",
    "\n",
    "    #add time attribute and concatenate results into new cube, write\n",
    "    dunits = 'days since %d-10-01 00:00:0.0' % (year-1)\n",
    "    t_unit = cf_units.Unit(dunits,calendar='gregorian')\n",
    "    time1 = iris.coords.DimCoord(np.arange(nt), standard_name='time', units=t_unit)\n",
    "    lat_agg = cube_mask.coord('latitude')\n",
    "    lon_agg = cube_mask.coord('longitude')\n",
    "    agg_cube = iris.cube.Cube(data_agg_3d,dim_coords_and_dims=[(time1,0),(lat_agg, 1),(lon_agg, 2)], \n",
    "                              long_name='snow water equivalent', var_name='swe', units='mm')\n",
    "    iris.save(agg_cube, outf,unlimited_dimensions='time')    \n",
    "\n",
    "    print \"Done writing %s\" % (outf)\n",
    "print \"Done with all years\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
